# infos.md

## 주요

### 알게 된 정보

#### Abstract Collection등등

````markdown
# Abstract Collection

## 2025.09.26

(주의 : 이 글에서 Abstract Collection은 스칼라가 실수 전체일수도 있음에도, 아니 사실상 기본적으로 유리수임은 깔고가는거에도 불구하고, 슬라이싱이나 인덱싱같은걸 할때, 범자연수처럼 취급합니다. 주의하세요.)

Abstract Collection이란 내가 발견한 연산인데, 나는 보통 배열류 객체를 프로그래밍의 컬렉션으로 보는 시각이 있다.

그런데 이제보니, Sequence나 Tuple이나 Vector나 공통된 추상적 속성이 있는것같다고 느끼고 발견한 추상적 객체를 지지난주쯤이 적어놨다.

처음 여러번 적다 정리한 Abstract Collection을 지난주 쯤에 완성된 서술본을 만들었고, 이번에 아예 github에 포스팅할겸 새롭게 적어놨다.

그래서 실제로 모델을 제시할때쯤 되야 이것인 그제서야 없는 대상에 대한 이상한 논의가 아니게 될것이다.

지금부터 말하는 내용들중에 근거를 찾을수 없는 내용은 전부 어쨌든 Ac의 성질에 따라 성립하는것이니,

추후에 사실상 대수구조인 모델 <Ac, -•, •[L], •[•], •[:•], •[•:], •[::•]>을 통하여 재대로 성질에 대한 공리계를 만들어 정의해야겠다고 생각한다.

어쨌든간에 나답게 맥락없이 바로 본론으로 들어가자.

Abstract Collection의 집합 Ac에 대해,

닫힌 연산인 Collection concat연산 •[•]은

∀A, B, C ∈ Ac, A[B[C]] = A[B][C] 이다.

즉, 결합법칙을 만족하므로, 반군을 이룬다.

Empty(=Blank) Collection ε에 대해,

A[ε] = A = ε[A]

즉, ε는 Collection concat연산의 항등원이다.

따라서, 반군이 항등원을 가지므로, 모노이드이다.

길이를 제는 연산은 ∀A ∈ Ac, A[L]인데, 이 연산 역시 닫혀있다.

그렇다. 보통의 연산에 대하여 A는 벡터공간을 이루므로, A[L] = 1c인 A는 Ac의 스칼라와 동형이다.

애초에 정의 자체가 SIMD연산처럼 배열간 잡연산이 처리되니 벡터공간을 이루는거지만 말이다.

중요한건 체 F위의 벡터공간은 합과 스칼라배만 정의되면 된다는거다.

스칼라 S에 대해 S¹, S², S³, ..., Sⁿ [n := ℵ₀]까지 싹다 합집합으로 묶은 백터공간인 셈이다.

정의상 벡터공간인 점에 주목해서 보자.

참고로, ε[L] = 0c이다.

참고로, 1c, 0c는 쌍대기저 c'가 A[L] = 1c인 A의 집합에서 스칼라로 가는 동형사상이므로, c' 1c = 1, c' 0c = 0인 1c, 0c이다.

그러나, Ac에서 벡터공간들의 기저공간의 기저는 차원 축에 대하여 유일하다.

그러니까, A[L] = 2c이고, 2c[L] = 1c이니, A = ac + bc₂일때, 기저 c, c₂는 2c, 1c에서 기저 c에 대해, {c}의 확장으로 {c, c₂}가 있는것으로 두 c는 같다.
그러니까, 진짜로 무한차원 벡터공간의 기저가 모든 차원을 죄다 생성한 벡터공간들의 합집합인 이 컬렉션 셋에서, 저차원의 공간은 국소적으로 축을 줄였을 뿐이지, 벡터공간을 이루게 하는 핵심 요소인 기저는 같은거다.

사실 길이가 같은 배열끼리만 벡터연산할꺼니까 달라도 되긴 하는데, 설명을 위해서 비표준적으로 같게 설정했다.

사실은 실제 정의상에서 기저는 다르다! 지금 저 "c"를 쓰고싶어서 저젛게 잡은거다. 표준적으로는 다르다.

벡터로써의 연산 *에 대해,
A, B, C = A * B에서,

first(x, y) = x
last(x, y) = y

를 정의하고,

tuple의 제귀적 정의에 따라,

first <x, y> = x
last <x, y> = y

이므로, 벡터에다가 first와 last를 적용할수 있음으로, 이를 통하여 C를 설명하겠다.

Ac에서 Vector연산은 정확히 Vectorized SIMD연산과 동형이다.

first C = (first A) * (first B)

이고

last C = (last A) * (last B)

이라는거다.

어찌보면 이쯤되면

사실상 A[L] = (dim A) c이지 않냐고 할수 있겠다.

뭐... 기저 c = 1c이므로 맞긴 하다.

그니까 이 벡터공간에서 유일하게 스칼라와 연산하는건 상수배밖에 없으며,

유일하게 길이가 다른 연산은 Ac의 고유연산이다.

행렬곱을 추가하면 되지 않느냐고 생각할수 있는데,

행렬이나 텐서를 코벡터로 취급하는 기법을 이용하여, rank-1텐서인 벡터공간 𝕍를 스칼라로 놓는다면, 그건 rank-2텐서인 행렬이고, 그걸 또 스칼라로 놓고 이런식으로 뇌절해서 구하면, 사실상 1 × n행렬, 즉 행벡터와 1 × 1행렬인 일차원 벡터를 곱하는것과 같으므로 보통을 필요성을 느끼지 못한다.
그럼에도 더 생각해보자면 결정적인 문제로, 벡터간의 곱셈은 n벡터와 n벡터사이의 상수배가 아닌 곱셈만이 정의되는데, 보통은 행렬표현을 한다면, 곱셈은 행렬곱으로 취급하므로, 행렬곱과 오인의 여지가 있기에 기호 혼용의 여지때문에 정의하기 더럽게 까다롭다.

그래서 사실 1×1행렬과 1×n행렬을 곱하는 시나리오도 같이 영원히 사요나라~ 하면서 정의하지 않은거다.

신기한걸 보여주겠다. •[L]은 다음과 같은 준동형사상이자 자기사상이다.

A[B][L] = A[L] + B[L]

그리고 영벡터들에 대해 생각해보자면,

(0A)[0B][L] = (0A)[L] + (0B)[L]

으로 자기동형사상이다.

마지막으로, functor ([L][L])는 상수함자인데,

A[L][L] = 1c이다.

그래서 지금부터 1c = codom ([L][L]) 으로 취급하겠다.

Collection reverse 연산자 -• 에 대해서, 

-(-A) = A이고 involution이다.

-(A[B]) = (-B)[-A] 를 만족한다.

(-A)[L] = A[L]이다.

Collection Slicing 연산자 •[•:]및 •[:•]및 •[::•]에 대해

A와 I[L] = A[L][L]에 대해, A[:I][L] = I이다.
또한, I ≤ A[L]일때, -(A[:I]) = (-A)[:A[L] - I]이다.

마치 처치 인코딩의 뺄셈같이 I > A[L]일때, -(A[:I]) = ε이다.

역정렬 연산자 - • 와 뺄셈을 명확히 구분하여 이해하도록 하자.

J[L] = I[L]이라면,

A[I:][J:] = A[I + J:]이고
A[:I][:J] = A[:I + J]이다.

사실상 자기사상 함자 [I:], [J:], [:I], [:J]에 대하여,

[I:][J:] = [I + J:], [:I][:J] = [:I + J]인

f(x) = [:x]혹은 f(x) = [x:]에서,

f가 f(x + y) = f(x) ◦ f(y)인 준동형사상이자 자기사상이다.

python에서 slice객체가 start:end:step순이듯, 여기서 •[::•]는 step순이다.

마치 python list x에 대해, y[n] = x[kn]인것같이 만드는것같은 심상이 든다.

A[::I][L] = k + I[L]은 A[L] ÷ I = k ••• (A[L] mod I)이듯이 k이다.

A[::I][::J] = A[::I×J]이다.

즉, [::I][::J] = [::I×J]로, 요것은 또, f(x) = [::x]일때

f가 f(I×J) = f(I) ◦ f(J)인 준동형사상이자 자기사상인것인거다.

A[I:][:I[L]] = A[:I+I[L]][I:]이다.

indexing처럼 생각하면 편하다.

[::I][J:][J[L]:] = [I×J:][:I[L]]이다.

다시한번 말하지만 마치 python list x에 대해, y[n] = x[kn]인것같이 만드는것같은 심상이 든다.

n벡터 A에 대해,

1. n + k = n
2. 0 - k = 0
3. -k = n - k
4. p × q > n이라면, p × q = n으로 한다.

라는 규칙을 추가해서, [0, n)범위의 자연수에서만 마치 셀처럼 작동하는 수 체계를 Collection Index System이라고 하겠다.

-f = (-•) ◦ f식으로 reversed연산자를 정의한 표기법을 Nero라고 하겠다. (작명은 내맘임 ㅋㅋ 검은고영이 네롴ㅋㅋㅋ Nego에서 g를 r로 바꿨다. 고양이가 연상되는게 마음에 들기 때문이... 사실은 지금 Night Dansor듣고있어서 감성이 충만해서 그런 감도 있고, 진짜로 ㄹㅇ로 작명은 완전 개썅마이웨이여서 그렇다.)

Nero와 Collection Index System에서,

-[:I] = [I:]이고,
[:I][:J] = [:I + J]이며,
[::I][::J] = [::I × J]이다.

[;]은 함자의 최초 입력을 뜻하고, [;][L]은 최초 입력의 값의 길이를 말한다.

따라서, [:[;][L]] = I이다.

사실 함자식 P에 대해, P(x)가 P([;]) [[;] := x]로 평가받는 셈이다.

나는 Collection Index System가 수직선상의 ln(x)스케일에서, 정의역을 n등분하여, 상한이 최댓값이고 그걸 n으로, 하한이 최솟값이고 그걸 0으로 하는 자연수 서수로 대응시킨 수 체계 집합같다고 느낀다.

그리고 •[•:], •[:•], •[::•], •[•], •[L]가 Collection Index System과 동형인 구석을 통해 대부분 설명된다고 본다.

아예 그냥 [X]식으로 함자를 만들면, 단항연산 •[L], (-•) 및 연산 •[•], •[:•], •[•:], •[::•]과 함자 [•], [:•], [•:], [::•]에 대하여, 동형성등 닮은구석이 많은 Collection Index System와 비교하는 방법으로 정리할수 있을것이라고 본다.

그러면 오늘은 "슬라이싱되는 무언가"에 대해, 지지난주 정도에 발견한 Ac를 적어보았다.

의사코드 예시로 python코드를 적고 끝내고싶지만 귀찮다.
(현 고딩인데 Python이 제2외국어 선택 과목인데 python을 평소에 안쓰고 공부도 전혀 안하는데 제2외국어 선택에서 저득점이아니라 만점맞고, 심지어 처음보는 라이브러리도 알아서 척척 이해할정도로 내부구조와 바이트코드 및 문서화 및 클린코드와 모듈화 및 라이브러리 제작법까지 다 아는 내가 python으로 프로그래밍하는데 어려움이 있는건 아니지만, 귀찮다고 하는건 작업이 쉬운데도 안하는것으로, 그냥 나태한거다. 돈을 굶겨봐야 정신을 차릴거다 아마도. 사실은 애니보고싶은데 동시에 작업하기는 귀찮아서 미룬거다. ~~이미 그러고 있지만~~)

나같으면 int랑 tuple을 다 상속받아서 연산을 구현한 후, ε, 0, 1은 기본적으로 클래스에서 상수처럼 가지고 있으며, __neg__에서, tuple->yield이용하거나 이터레이터 이용하여 역방향->tuple해주고, __getitem__에서 len을 받아서 len(self)해주며, 여러 연산들을 구현해야하는데, 굳이 그런 괴상한짓을 할 이유가 무엇인지 모르겠다.

개다가 젠장할, slice부분에서, 음수를 넣지 말아야하며, start, end, step부분을 각각 적절히 우리 시스템에 맞게 python타깃으로 컴파일하여, start는 길이 이상이면 ε를, end는 0이면 ε를 리턴하는 아주 개꼴받게 힘든짓을 해야한다.

결정적으로 [;]같은 노테이션이 안통하고, Collection Index System같은 경우 int비스므리한 자료구조를 하나 더 만들어야 한다.

다음번에는 그 귀찮은 과정을 직접 해와서 코드를 적을것이다.

그렇기에 마크다운에서도 `###`가 아닌 `####`로 된 곳에 날짜를 적어서 이 글을 부연설명하는 문단정도로 만들거다.

아마 곧 만들어올거다.
````

#### 어떤 대수학 명제는 ε-δ 없이 증명 • 반증 불가

초월수와 실수의 완비성 관련된 부분.

어떤 대수학 명제는 ε-δ 없이 증명될수 없음을 밝힌 점.

````markdown
# Euler

```
Fact) ¬p ∧ p ↔ ⊥
Fact) ¬(±1 = +1) ↔ (±1 = -1)
p.f. 결론을 부정하여, p = (±1 = +1)에서, q = (±1 = -1) ≠ p로 놓자.
그러면, p ∧ q ↔⊥이므로, p와 q는 모순관계에 있으므로, 결론을 부정하면 거짓임을 알 수 있다.
Q.E.D.
Fact) (¬p → q), (p → q) ⊨ q
Fact) ((±1 = +1) → q, (±1 = -1) → q) ⊨ q
p.f. 항진명제를 늘어트려서 이야기하자면, ¬(±1 = +1) ↔ (±1 = -1)이고, (¬p → q), (p → q) ⊨ q이므로,
p = (±1 = +1)로 대입하면,
((¬p → q), (p → q) ⊨ q) ↔ (((±1 = +1) → q, (±1 = -1) → q) ⊨ q)이므로, 결과도 항진명제다.
Q.E.D.
Fact) z = x + yi이면 z̄ = x - yi
pf. z̄의 정의가 z = x + yi인 z에 대해, x - yi이므로,
z = x + yi이면 z̄ = x - yi
Q.E.D.
Fact) ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2iᵗ)x + ((1∓1)/2iᵗ⁻¹)y [t := ((1∓1)/2)]
p.f. 결합법칙, 분배법칙, 교환법칙, 결합법칙, 분배법칙, 곱셈의 교환법칙, 곱셈의 교환법칙 순으로 적용하여 계산하면,
((x + yi) ± (x - yi))/2iᵗ [t := ((1∓1)/2)]
 = (x + yi ± (x - yi))/2iᵗ [t := ((1∓1)/2)]
 = (x + yi ± x ∓ yi)/2iᵗ [t := ((1∓1)/2)]
 = (x ± x + yi ∓ yi)/2iᵗ [t := ((1∓1)/2)]
 = ((x ± x) + (yi ∓ yi))/2iᵗ [t := ((1∓1)/2)]
 = (1±1)x/2iᵗ + (1∓1)yi/2iᵗ [t := ((1∓1)/2)]
 = ((1±1)/2iᵗ)x + ((1∓1)/2iᵗ)yi [t := ((1∓1)/2)]
 = ((1±1)/2iᵗ)x + ((1∓1)/2iᵗ⁻¹)y [t := ((1∓1)/2)]
Q.E.D.
Fact) ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2)x + ((1∓1)/2i¹⁻ᵗ)y) [t := ((1∓1)/2)]
p.f. ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2iᵗ)x + ((1∓1)/2i¹⁻ᵗ)y [t := ((1∓1)/2)]일때 ((1±1)/2iᵗ)x + ((1∓1)/2i¹⁻ᵗ)y = ((1±1)/2)x + ((1∓1)/2)y를 증명하면, 증명할수 있기에, ((±1 = +1) → q, (±1 = -1) → q) ⊨ q에서, q에 맞는 논리식을 계산하면,
±1 = +1일시) ((1±1)/2iᵗ)x + ((1∓1)/2i¹⁻ᵗ)y = ((1+1)/2iᵗ)x + ((1-1)/2i¹⁻ᵗ)y = x = ((1+1)/2)x + ((1-1)/2)y = ((1±1)/2)x + ((1∓1)/2)y [t := (1∓1)/2 (=(1-1)/2 =0)]
±1 = -1일시) ((1±1)/2iᵗ)x + ((1∓1)/2i¹⁻ᵗ)y = ((1+1)/2iᵗ)x + ((1-1)/2i¹⁻ᵗ)y = x = ((1+1)/2)x + ((1-1)/2)y = ((1±1)/2)x + ((1∓1)/2)y [t := (1∓1)/2 (=(1-1)/2)]
따라서, q = ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2)x + ((1∓1)/2i¹⁻ᵗ)y)
Q.E.D.
Fact) z = x + yi일때, (z ± z̄)/2iᵗ = ((1±1)/2)x + ((1∓1)/2)y [t := ((1∓1)/2)]
p.f. z = x + yi이면 z̄ = x - yi이고, ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2)x + ((1∓1)/2i¹⁻ᵗ)y) [t := ((1∓1)/2)]이므로,
대입법을 이용하여 풀면,
(z ± z̄)/2iᵗ = ((x + yi) ± (x - yi))/2iᵗ = ((1±1)/2)x + ((1∓1)/2)y [t := ((1∓1)/2)]이다.
Q.E.D.
Fact) z = cis θ에서, z̄ = cis(-θ)
p.f. cos는 우함수, sin는 기함수이므로,
z = cis θ에서,
cis(-θ) = cos(-θ) + sin(-θ) = cosθ - i sinθ = z̄
Q.E.D.
Fact) z = cis θ에서, z̄ = z⁻¹
pf. z = cis θ에서, z̄ = cis(-θ)이므로,
(cis θ)⁻¹ = cis(-θ) = z̄
Q.E.D.

Φ(z) : z ± 1/z = (z² ± 1)/z
Ψ(x, y, z) : z = x + yi ⊨ (z ± z̄)/2iᵗ = ((1±1)/2)x + ((1∓1)/2)y [t := ((1∓1)/2)]
P(z) : z̄ = 1/z
Θ(x, y, z) : Φ(z), Ψ(x, y, z), P(z)

Fact) P(z) ↔ (zz̄ = 1)
Fact) Θ(cos θ, sin θ, cis θ)
p.f. 나머지는 전부 항진이니, P(z) ↔ (zz̄ = 1)에서,
cisθ × cis(-θ) = cos²θ + sin²θ = 1
Q.E.D.
Fact) zz̄ = 1 ↔ z = cisθ
pf. 양방향함의는 논리적 동등 기호 `↔`이기에 분해 가능
1. zz̄ ≠ 1에서, cisθ × cis(-θ) = cos²θ + sin²θ = 1로 모순이므로, zz̄ = 1 → z = cisθ
2. z̄cisθ ≠ 1에서 zz̄ = 1일때, z = cisθ이므로, 모순.
```

Q.E.D.

질문 : 그렇다면 f(n) = aⁿ이 주기함수라면, cis(τn/T)로 표현 가능한가?
````

답변 : 그건 초월수와 실수의 완비성을 건드려서 ε-δ를 꺼내게 한다.

어떤 점 변항이 0에 한없이 근접하는 행태를 보이기 때문이다


## 부가

### 수학의 메타분석 구조

SemiProbability와 UBDG라는 수학의 메타분석 구조를 소개한다.

이 구조가 왜 발생하는지 솔찍히말하자면 너무 궁금하다.

#### SemiProbability

```markdown
# semiProbability and ㄴStatisticalMetaSystem

일단 말하기 앞서 다음과 같이 공리적 확률론을 분할할 생각임.

Kolmogorov’s axioms
 - Probability (including contingent proposition)
 - semiProbability (allow only formal proposition)

## semiProbability on DiscreteUniformDistribution (DUD-semiProb)

표본공간 Ω가 이산균등분포인 경우다.
이 경우 역시 두가지로 나누겠다.

DUD-semiProb
 - Finite-DUDSemiProb (|Ω| < ℵ₀)
 - infinite-DUDSemiProb (|Ω| = ℵ₀)

### Finite-DUDSemiProb (F-DUD-SmPr)

이 경우에는 매우 특이한 상황이 된다.

P(Φ)가 Φ일 확률이라고 치면,

P(Φ) = |Mod(Φ)|/|Ω|

를 만족하기 때문이다.

따라서 이때 두가지를 정의하겠다.

ㄴSIZE ≜ |Ω|
ㄴNumberOfCase ≜ ㄴSIZE P

굳이 `ㄴ`을 쓴 이유는 원래는 `ㄱSIZE`, `ㄱNumberOfCase`와 같이 써서 혹시모를 중복을 피하려고 했는데, `ㄱ`이 부정(Nagation) 기호같이 생긴 탓에 `ㄴ`을 골랐다.

표본공간의 측도가 ㄴSIZE이 되고, 경우의 수가 ㄴNumberOfCase가 되는데, P(Φ) = |Mod(Φ)|/|Ω|이기에,
이런 P를 ㄴSIZE배 해준 ㄴSIZE P는  |Mod(Φ)|이기에, ㄴNumberOfCase는 |Mod(Φ)|이다.

이렇게 두가지 심볼 ㄴSIZE 및 ㄴNumberOfCase가 정의된 모델을 ㄴStatisticalMetaSystem 이라 하겠다.

#### ㄴStatisticalMetaSystem (semiProbability에서 새로 정의한 ZFC를 분석하는 Meta System. (사실상 Model이고 확률론 공리계의 Extension처럼 동작하지만, 그냥 메타적으로 분석하니까 메타시스템이라고 함.))

ㄴStatisticalMetaSystem는 다음 Symbol이 정의되고 다음 Axiom이 만족된 Kolmogorov’s Axioms & ZFC 위의 Model Structure이다.

1. Constant Symbol Assignment

ㄴSIZE ≜ |Ω|

2. Function Symbol Assignment

ㄴNumberOfCase ≜ ㄴSIZE P

3. ㄴStatisticalMetaSystem Axioms

∀A ⊆ Ω, P(A) = |A|/|Ω|

4. ㄴSMS Notation (선택사항, 그냥 표기 방식 명시)

ㄴNumberOfCase(Predicate)
 = ㄴNumberOfCase(Predicate ∩ Ω
 = ㄴNumberOfCase(Mod(Predicate) ∩ Ω)

식으로, 어떤 명제를 술어로 다루겠다는거. 어짜피 술어가 집합이니까 이 표기법은 옳은 표기법이지만, 명확히 할 필요가 있음.

이하에서, ㄴSIZE = t면, 그 ㄴStatisticalMetaSystem을 t-ㄴSMS 라고 하겠다.

t-ㄴSMS에서, 케이스의 수 (ㄴNumberOfCase)는 술어(=문장)가 만족되는 케이스의 수이기에, 모델집합의 카디널을 다루는것이다.

또한 이건, ZFC에 대한 메타분석처럼 볼 수도 있다. 판단 대상이 ZFC상의 논리를 가지고, 모델집합의 측도를 분석하기 때문이다.

매우 흥미롭고, 조심해야할것같다.
```

#### UBDG (a.k.a. 과학구조)

```markdown
# 과학구조 (유추 구조, 가정구조공리술어, 통계구조생성자, 귀추 구조)

유추 구조, 가정 구조, 귀추 구조는 각각 수학적 수식 혹은 술어이거나 대수 구조이다.

그러니까 과학구조는 탐구방법론같은 시시콜콜한 과학자들의 좆 비스무리한 개쓰래기 똥 씨발 멍청한 찐따같은 씨발 좆이 아니라 그냥 Fuck도 아니고 과학이라는 Fuck 똥 씨발 좆 좆 좆이 아니라 씨발 그런 개같은게 아니라, 술어 혹은 시시콜콜하고 좆같은 술어보다는 사실은 대수구조 및 대수에서 구성한 함수(연산)이다. 그러니까 모델론 및 범주론 및 추상대수학적인 연구 대상이다.

통계 구조는 유추 구조로 만들어지며 그러지 않는다면 빛 좋은 개살구다. (통계적 구조는 퍼지논리 공리계의 모델을 제시하는 전혀 다른 통계의 언어로 구성한 수학 언어를 쓰는데 이것이 무려 일반 수학의 확장이다. 따라서 나는 연역법 만능주의자기 때문에 이런걸 좆같아해서 통계적 구조를 유추 구조로 환원해서 연역화하지 않고 제시한다면 내가 당신 목따러 달려갈수도 있다.)

N.B. 씨발씨발 좆좆같네 아아아악이거는 절대 좆 shit 등신같은 과학이 아니라 과학처럼 보이는 ZFC및 Alkalic공리계 공통기반 공리이용 추론 혹은 자연연역법을 통한 특정한 추론(유추 구조에서 말하는 추론, 가정구조에서 말하는 추론, 귀추구조에서 말하는 추론)의 대수구조화라고 보면, 어느정도 맞는데 틀리다. 이거는 추론의 대수구조화 그 똥같은게 아니라, 그냥 대수구조다. 여기서 추론을 붙이는것은 금지된다. 의미론적으로 추론으로 규정해버리는 순간 대수구조의 의미가 아니기에, 여기서 정의하는 내용은 대수구조지 좆같이 추론에 간섭하는게 아니라고 해두겠다.

씨발 좆좆좆같은 추론내용에 대한 간섭 싫어

## 유추 구조

Zhegalkin Polynomial에서,

Φₙ : "n번째 관측된 결과"에서,

Ψₙ(Φ) ≜ Πₖ Φₖ [k := 1 ~ n]로 정의하고,

lim Ψₖ(Φ) : ∀n ∈ ℕ, Φₙ (k → ∞)
이므로, 이러한 Ψ를 유추 구조라 한다.

## 통계 구조

정해진 y에 대해, x ↔ y를 FuzzyLogic으로 쓰면,

x ↔ y ~ B(n, pmf(x))이므로,

부울 도메인을 실수로 확장한 Alkalic논리는 실수로 확장됬으니까, 이 경우에 한정하여 원래 불 도메인인 {0, 1}에서와 달리 FuzzyLogic및 확률과 통계의 확률 개념과 동형이다.

따라서,

Alkalic논리에서의 (x ↔ y) = (x = y)로 놓는 순간, Alaklic이 FuzzyLogic을 따르고, x와 y는 확률과 통계의 연언명제가 될 수 있음이 당연하다.

따라서,

H : (x ↔ y) = (x = y)에 대해,

Alkalic에서 논리언어의 모델을 H로 바꿔놓는 개짓거리를 하는 순간, 유추 구조를 통계 구조라고 하고, 이는 수학을 모호하게 만든다. (그니까 H를 공리화하는 좆같은거다, 이게 통계 구조의 포괄적 정의다, 즉, 쓸모없는 좆을 포함한 포괄적 정의.)

통계 구조의 정의는 아래 참고.

### 왜 쓰나?

통계 구조 S(X)에 대해, 이 통계 구조가 본래의 부울 도메인 {0, 1}에서 정상작동할것이므로,

일반적인 Alkalic수학에서 유추구조를 정의한 모델 X만을 정의역으로 하는 S에 대해, (S는 statistics)

S(X) = Y s.t. Alkalic에서 논리언어의 모델을 H로 바꿔놓는 개짓거리를 한것

이고, 이때,

A)
항상 우연명제일줄 알았던 참인 가정을 입력시키는데에 있어 적절한 추론을 썻다면, S(X)가 디렉델타함수의 평행이동으로 동작하며, 동시에, 당연히 이분논리적인 결과가 나오기 때문에

B)
즉, 확률적 추측이 아닌, 통계적 관찰에서 통계는 빼고 관찰만 가지고 연역적 추론을 한 이분논리적 연역법이기에, 건전하게 되는 상황과 동등하기에 (Tip : A ↔ B임)

이에따라서, 무한시도의 무한발생이라는 보편양화적인 과정에 따라서 참이 될 수 있다.

즉, X에서의 Ψ를 S(X)에서의 Ψ로 옮기면, 이것 역시 큰 수의 법칙을 따르며, 심지어 극한을 보내면 연역법이다.

함수 S가 바로 "통계구조생성자"이며, 이것이 통계구조의 정의이다.

#### 그래서 왜 큰 수의 법칙을 따르는걸 만들어놓느냐?

귀추 구조로 유추 구조 Ψ가 의미하는 바가 가설이라는 귀추 구조를 만들수 있기 때문이다.

## 가정 구조

다음 술어 μ를 보라.
μ(H) : Ψ(Φ) = H ∧ (⊨Ψ(Φ))

μ(H)를 가설로 놓아 공리를 설정하는 귀추 구조를 가정 구조하고 한다.

그리고 μ는 "가정구조공리술어"라고 한다.

#### 가정구조 한줄요약 = 가정구조공리술어 한줄요약

"유추구조에서 계량하는 명제가 바로 가설 H이다."는 귀추구조용 공리.

원래 유추구조에서 판단 불가능한걸 의미해석 중간에 빼돌려서 가능하게 함.

## 귀추 구조

가설을 공리로 증명하는 규칙도입계 모델 M을 만들고,

1. M이 일관됬는가?
2. M이 증명하고자 하는 공리계와 호환되는가?
3. M이 증명하고자 하는 공리계에서 증명가능한가?

절차로 만족시키면, 증명될것이므로, 이러한 M을 귀추 구조라고 한다.

## 마치며

Q. 추론의 모델링인가요?
A. 그냥 대수구조가지고 추론을 모델링했다? 지랄하네 목적에 벗어나는 과대해석이지? 그냥 어떤 추론과정을 모델링한것과 같은 결과라고 하면 뭐 맞긴한데 그게 핵심이 아니라고. 핵심은, 내가 추론에 대해서 탐구하는중에 대수구조를 하나 발견한거고, 저건 추론이 아니라 대수구조야. 씨발 추론을 모델링한 목적에 충실하지 않은데 뮤ㅓㄴ 개소리야? 에초에 만들어진 이유가 우연히 발견한 대수구조이고, 그 대수구조는 추론의 목적의 충실하지 않으니 수정해야하네가 개소리된다 죽어버려 개씨발아!! 개소리하지마!! 거짓 거짓 거짓!! 추론의 모델링? 아니오 아니오아니오 씨발아 아닙니다!
Q. 추론 과정을 모델링한것과 같은 결과네요?
A. 개씨발새끼야 그럼 미적분은 미분소로 하는게 참이고 무한소쓰는게 표준해석하기겠지 죽어라!! 미적분이 역사적으로 무한소를 쎴지, 초실수체를 다루는 연상이 아닌 δ-ε논법적 연산인것처럼, 과학구조도, 전혀 추론과정따위 좆을 다루능게 아니라 그냥 평범하게 규칙도입계 대수를 이용한 대수구조라고요!!

이 저주받은건 이름부터 "우연이발견한대수구조"(UBDG : U연이 Bar견한 Desu gujo)로 해서 UBDG₀, UBDG₁, UBDG₂, UBDG₃로 고쳐여겠어. 이름이 하느님아버지와 예수님의 분노를 사서 저주받았기에 이렇게 오해받는걸꺼야.
```

## 대수

### 대수학

```markdown
# 다항식은 좋다가도 싫다.

대수적 난이도만 다룬다.

## 일차식 ~ 사차식

즉, 근의공식이 존재하는것들만

1. 근의공식에 대해
2. 인수분헤에 대해
3. 다항식 수식에 대해
4. 다항방정식에 대해
5. 다항함수에 대해
6. 그 그래프에 대해
7. 기본적 응용에 대해

다룬다.

### 일차식

해당하는 노트가 아직 없다.

### 이차식

이차함수는 짝(Even)함수(Func) (즉, 우함수)로, 비선형 다항차수 다항식 중에서, 유일하게 평행이동만으로 xⁿ꼴에서 만들수 있다.

이차함수의 그래프를 대칭이동할때, 표준형 완전제곱식 항의 계수, 즉, 최고차항이었던 것(사실은 q = c - ap²라서, a를 빠꾸면 안됨)에 부호를 플립시 y축 대칭, p의 부호를 바꾸면, x축 대칭이다.

y = a(x - α)(x - β) = ax² + bx + c = a(x - p)² + q꼴로 생각해야 전체를 볼 수 있다.

#### 이차식의 특징

x에 대한 완전제곱식 y에 대해 y에 대한 합차공식 꼴로,

q = -D/4a에서, 완전제곱식이 중근을 가지고, 실근을 하나밖에 안가지는 기하적 위치에 있음을 알 수 있다.

q < 0에서, 실근이 두가지이고, q > 0에서 허근이 두가지다.

이에따라서,

(b/2)² = ac일 조건이 무슨 조건인지는 D/4와 D에 따라, 쉽게 알 수 있다.

(ax + b)(cx + d) = acx² + (ad + bc)x + bd = Ax² + Bx + C에서,

+ A = ac
+ B = ad + bc
+ C = bd

(사실 이차함수는 조립제법 안쓰고, 한 근을 주었을때 풀이가능할정도 난이도다, 저 구조에서, 어느 하나에 대해 시도시 잘 구해지므로, 저걸로 풀이가 쉬운 이유.)

이므로, 일차식의 곱 꼴인

y = Πₖ (x Aₖ + Bₖ)중에서 유일하게 써먹을 만한 난이도다.

(ax + b)(cx + d) = ac(x + b/a)(x + d/c)에서, ac = t로 두면 이해가 쉽다.

이런 구조로써, 근의공식도 유도된다.

#### 이차함수의 최대 • 최소

+ y = f(x) = a(x - p)² + q
+ P = (n, m)
+ Q = (inf f(x), sup f(x)) (x ∈ P)
일 때, x ∈ P → y ∈ Q임.

n = p - b, m = p + d 일때,

명제 Φ : inf Q = q 에 대해,
+ Φ일때, t = sup Q
+ 아닐때, t = inf Q로,
q를 극값 경계, t를 비극값 경계로 명명하겠음.

그러나, p < n < m이거나, n < m < p인 경우, 극값 경계니 뭐니는 의미 없다.

y = ax² + bx + c = a(x - p)² + q 에서,

b = -2ap이므로, 취른하우스 변환에서 나왔던 공식,
p = -b/2a를 얻을수 있고,

x에 단순히 p를 대입해, q를 구할 수 있다.

만약 극값 경계니 뭐니 논하는 문제가 아니면, q를 구할필요가 없고, a를 이용하여 증가 감소를 생각해야하므로, 다음 결론을 얻는다.

case₁ : n < m < p
case₂ : n < p < m
case₃ : p < n < m

case₂의 경우
1. a > 0일때
 - 극값 경계가 하한
 - 비극값 경계가 상한이고, f(p ± k) 가능한한 큰 k
2. a < 0일때
 - 극값 경계가 상한
 - 비극값 경계가 하한이고, f(p ± k) 가능한한 큰 k

case₂가 아니면, 
1. case₁시
 - a > 0시 감소로, f(m) < f(n)
 - a < 0시 증가로, f(n) < f(m)
2. case₃시
 - a > 0시 증가로, f(n) < f(m)
 - a < 0시 감소로, f(m) < f(n)

(n다음 m을 쓴건, 자주 쓰이는 순서로 간 게 아니라, 내가 알파벳 순서대로 해야하는걸, 습관적으로 n, m순서로 썼다는거)

### 삼차식

이것도 해당하는 노트 없다.

다만, (u + v)³ = u³ + v³ + 3uv(u + v)를 르네상스 시기에 아름답다고 수학자들이 생각했으며,
타르탈리아가 이를 통해, x³ + px = -q의 해를, x³과 x에, x := u + v하므로 구하고,
카르다노가 쌔벼서 연구한 후, 재대로 된 훌륭하고 칭송받을만한, 삼차방정식 근의 공식으로 만들었다는데에서,

당시 수치나 수학의 대칭성에 주목하던 시선이 과연 무었인지,
추론해보면, 이부분에 대해 작성할 가능성이 있다.

### 사차식

여기서는, 나는, X² + aX + b [X := x²]꼴의 사차식 수식에 주목된다.

이차함수 f, g에 대하여, f(g(x))꼴의 수식으로,

다항함수 f, g에 대해여, f(g(x))꼴이 f및 g보다 차수가 높은 동시에, 일반해를 구하는 대수적 공식을 가지려면, f및 g가 선형함수보다 차수가 높은데에다가, f(g(x))가 사차함수 이하여야 하므로, 이차함수 f, g에 대하여, f(g(x))꼴의 수식이 대표적이다.

1. 카르다노의 제자 페라리가, 사차식을 완전제곱식으로 강제로 분해하는 과정에서, 삼차방정식 근의 공식을 썼고
2. 타리탈리아는 삼차방정식 x³ + px = -q의 해법을 구할때, -p = 3uv와, -q = u³ + v³에서 이차방정식의 근의 공식을 썼으며
3. 이차방정식의 근의 공식을, 완전제곱식으로 만드는 방법(팁 : 취른하우스 변환은, 이차식을 완전제곱식의 합차공식꼴로 만든다)으로 유도할 때, 일차방정식의 해법을 이용하므로,

흥미로움을 떨칠수가 없다.

그래서 삼차식 탐구 이후에 알아보려 한다.

단지 헬조선에서 대학은 가야 곱게보는 미친 나라이니까, 공부해야해서 미룰거임.

## 식을 만드는 꼴

### xⁿ에 직접적으로 연관된것

완전제곱식(다항정리), 합차공식꼴(xⁿ ± yⁿ꼴)을 말한다.

이항정리꼴, 이항 아니고 삼항공식꼴, 다항공식꼴, 합차공식꼴, 완전제곱식, 완전세제곱식, 완전 내제곱식, 합차공식, x³ ± y³, x⁴ - y⁴로 분류한다.

#### 완전제곱식

(x ± y)² = x² ± 2xy + y² 꼴이다.

아 짜증나 지금 쓰기 싫어

#### 완전 세제곱식

(x ± y)³ = x³ ± 3x²y + 3xy² ± y³

(u ± v)³ = u³ ± v³ ± 3uv(u ± v)

이꼴을 굳이 지금 할 필요가 없다. 나는 이걸 이미 미뤘다고 말한 바 있다.
```

### 해석학 • 미적분학 ; 극한

#### 합성함수의 극한

```markdown
# 합성함수의 미분 하나 다루겠다고 복잡하게 식쓴거

001 | 

002 | Definition) 함수 y = f(x)가 그리는 도형 위의 정점 P₀(x₀, f(x₀))부터 정점 P₁(x₁, f(x₁))까지 동점 P가 움직였을때, 

003 | P₀ + <Δx, Δy> = P₁을 만족하는 Δx, Δy를 각각 x와 y의 증분이라고 정의한다.

004 | 

005 | Definition) 함수 y = f(x)에서 차분 Δf(x) ≜ Δf(x₀) ≜ Δy [x₀ := x] 로 정의한다.

006 | 

007 | P₀, P₁, <Δx, Δy> 이중 두가지만 결정되더라도 Vector의 덧•뺄셈은 SIMD마냥 x-y축이라는 요소 종류중에서 같은 종류의 요소에만 연산되기에, 완벽히 해당 스칼라에서의 덧•뺄셈을 흉내내기에, 나머지 하나가 결정된다 (대수구조 중 Loop)

008 | 

009 | 함수 y = f(x)에 대해, 그 정의역 위에 x₁, x₂가 존재하여, y₁ = f(x₁), y₂ = f(x₂)를 만족한다면, 함수라는것은 반드시 x₁ = x₂ → y₁ = y₂를 만족한다.

010 | 

011 | 즉, 정의역 위의 x₁에 대해 card {y | y = f(x)} = 1이다. 함수값은 매개변수의 값에 의해 하나로 결정된다.

012 | 

013 | 따라서, x₀, x₁에 대해 각각 y₀, y₁는 하나씩 결정된다.

014 | 

015 | 즉, x₀, x₁, Δx중 어느 두가지만 결정되어도, P₀, P₁, <Δx, Δy>가 다 결정된다.

016 | 

017 | 그러므로, 

018 | 

019 | P₀ + <Δx, Δy> = P₁

020 | = <x₀, y₀> + <Δx, Δy> = <x₁, y₁>

021 | 

022 | 애서, 

023 | 

024 | <Δx, Δy> = P₁ - P₀

025 | = <x₁, y₁> - <x₀, y₀> = <x₁ - x₀, y₁ - y₀>

026 |  = <x₁ - x₀, f(x₁) - f(x₀)>

027 | 

028 | 이다.

029 | 

030 | 따라서, 평균변화율 Δy/Δx = (f(x₁) - f(x₀))/(x₁ - x₀)이 x₀, x₁, Δx중 어느 두가지가 결정되면 결정된다.

031 | 

032 | 사실, x₀ + Δx = x₁, Δx = x₁ - x₀을 만족하므로, x₀이 정해졌을때나 x₁이 정해졌을때, 각각 x₁과 x₀은 Δx와 일정한 차나 일정한 합을 가지는 관계이고,

033 | 

034 | 특히, x = x₀인 차분에서, x₀ + Δx = x₁로 x₁이 결정된다.

035 | 

036 | 사실은, 이 정의는 일부러 "P₀, P₁ ∈ graph f ∧ P₀ + <Δx, Δy> = P₁"라는 기하적으로 증분을 정의한것이므로, 일부러 x₁ 혹은 Δx를 건드려줄것을 기대하고 만든 증분의 정의로, x₁, y₁및 x₀, y₀의 함수관계와, Δx증분관계 하에 놓인 함수 graph상의 변수들의 관계 선언한것이지, 어떤 정상적인 함수나 변수를 선언한것이 아니다. 따라서, 앞으로 나올 x₁, y₁, x₀, y₀, Δx, Δy는 아주 기깔나게 자유변항마냥 조작되는 모습을 볼 수 있을것이다.

037 | 

038 | 앞으로 증분 Δx, Δy를 건드린다면, x-y 평면상의 graph f위의 동점의 이동에 따른 벡터 증가량으로 표시될것이다.

039 | 

040 | Definition 교육과정상 미분과 계수) $y = f(x)에 대해, (d/dx f(x)) ≜ dy/dx ≜ lim_{Δx → 0} Δy/Δx$ (Tip : 입출력 축은 달라질 수 있음)

041 | 

042 | 여기서 정의한 차분에 따라서,

043 | $lim_{Δx → 0} Δy/Δx = lim_{Δx → 0} (f(x + Δx) - f(x))/Δx$

044 | 

045 | 또한, 여기서 정의한 증분에 따라,

046 | $lim_{Δx → 0} Δy/Δx = lim_{t → x} (f(t) - f(x))/(t - x)$

047 | 

048 | 이런식으로 동작하게 해놨다.

049 | 이것 역시 x축과 y축이 아닌 다른 축의 원소다 미지수가 되면 기호를 dx, dy에서 다른걸로 바꾼다.

050 | 

051 | Theorem 합성함수의 미분법) (f◦g)' = g' × (f'◦g)

052 | Proof) 합성함수의 미분법을 증명해보자.

053 | 

054 | 미분할것을 목표로 하는 함수는 y = (f◦g)(x)이다.

055 | 

056 | 그래프 위에서 도형을 그리는 다음 연립방정식 y = f(u), u = g(x)을 살펴보자. 미지수 u가 생김에 따라서, 가상의 u축이 더해진 상태이다.

057 | 

058 | 이제 함수는 음함수꼴에서, 그래프 graph f를 술어로 간주하여, (graph f)(x, u, y)를 (graph f)(u, y) : (∀x (graph f)(x, u, y)) 로 표기하여 간주하고,

059 | 

060 | graph g를 술어로 간주하여, (graph g)(x, u, y)를 (graph g)(x, u) : (∀y (graph g)(x, u, y)) 로 표기하여 간주한다.

061 | 

062 | 그 이유는 (graph f)(u, y)및 (graph g)(x, u)및 (graph (f◦g))(x, y)에서, 미지수를 저 꼬라지로 만들었기에, output = function(input)꼴을 만들고, 각 축에대해 값을 표기하는, 즉, 음함수 graph f의 해(근), 즉, 음함수꼴을 만족시키는 값이

063 | {(input, output) | output = function(input)}꼴인데, 세가지 함수를 연립하면, 각각의 미지수에 대한 관계로 graph로 만든 술어관계가 변하므로,

064 | 음함수꼴을 만족하는 점이 사용되지 않는 변수의 축도 존재하여야 한다.

065 | 

066 | y₀ = f(u₀), u₀ = g(x₀)이라면, 

067 | 

068 | (x₀, u₀, y₀) ⊨ (y = f(u), u = g(x))여야 한다.

069 | 

070 | 사실, 음함수가 관계 역할을 함으로, 그 음함수 "(y = f(u), u = g(x))"에 대해, (y = f(u), u = g(x))(x₀, u₀, y₀)을 만족한다는건, (y = f(u), u = g(x)) ⊆ 𝕏 × 𝕌 × 𝕐 (단. (x, u, y) ∈ 𝕏 × 𝕌 × 𝕐)이기에,

071 | 

072 | (x₀, u₀, y₀)가 (x = x₀, u = u₀, y = y₀)로 동작함은 누구나 알것이다.

073 | 

074 | 사실 저 구조체같은게 튜플이던 아니던, 걍 내부 문장들을 전부 연언해주면, 논리적 귀결같이 작동하는건 똫같으므로, 굳이 태글걸 곳도 없다.

075 | 

076 | y = f(u), u = g(x) 이면이 y = f(g(x)) 이므로, 두 식 y = f(u), u = g(x) 을 연립한 좌표평면 위의 도형 y = f(g(x))은 y = f(g(x))가 그리는 그래프와 같다.

077 | 

078 | 이하에서, y = f(g(x))는 두 식 y = f(u), u = g(x) 을 연립한 좌표평면 위의 도형과 동일하게 보겠다.

079 | 

080 | 함수 y = f(g(x))의 미분은, $dy/dx = lim_{Δx → 0} Δy/Δx$ 이다

081 | 

082 | 그런데

083 | 

084 | 함수 u = g(x)에 대해, 그 미분이 $du/dx = lim_{Δx → 0} Δu/Δx$ 이고

085 | 함수 y = f(u)에 대해, 그 미분이 $dy/du = lin_{Δu → 0} Δy/Δu$ 이다. ⋯ ①

086 | 

087 | 평균변화율에서, Δx, Δy, Δu가 다 연동이 되게 선언하였으니,

088 | 

089 | Δy/Δu × Δu/Δx = Δy/Δx 이므로,

090 | 

091 | x-u 평면상의 함수 u = g(x)에서

092 | 

093 | Δx → 0일때 분모 → 0이므로 분자 → 0이여야 한다.

094 | 

095 | 즉, Δx → 0에서, Δu → 0이다.

096 | 

097 | 따라서, 함수 y = f(g(x))에서

098 | 

099 | 미분계수 $dy/dx = lim_{Δx → 0} Δy/Δx = lim_{Δx → 0} (Δy/Δu) (Δu/Δx)$ 는

100 | 1. Δx → 0일때, Δu → 0이고

101 | 2. $lim_{Δx → 0} Δu/Δx = du/dx$이며

102 | 3. $lim_{Δu → 0} Δy/Δu = dy/du$이기에,

103 | 

104 | 극한의 성질 $lim_{x → a} [f(x) g(x)] = [lim_{x → a} f(x)] [lim_{x → a} g(x)]$에 따라서,

105 | 

106 | $dy/dx = lim_{Δx → 0} (Δy/Δu) (Δu/Δx) = [lim_{Δx → 0} (Δy/Δu)] × [d/dx g]$ 이다.

107 | 

108 | 이제 남은 식을 풀이해야함은 당연히 그것이 목적이니 당연하다.

109 | 그러기 위해서 $lim_{Δx → 0} Δy/Δu$에서의 식의 꼴을 알아내기 위해 Δu의 값을 구해야 한다.

110 | 사실은 누구나 직관적으로 알았겠지만 0/0꼴이다.

111 | 왜냐하면 기존의 정보 Δx → 0에서 Δu → 0, 즉, $lim_{Δx → 0} Δu = 0$을 만족하므로, 0/0 꼴이 되는것은,

112 | 

113 | 1. $lim_{Δx → 0} Δy = 0$

114 | 2. $lim_{Δx → 0} Δu = 0$

115 | 에서, 이미 그 두 충분조건이 마련된 논리적 귀결이기 때문이다. (참고 : 0/0꼴은 $lim_{x → a} [분자/분모]$ 식에서, x → a일때, 분자 → 0이고, x → a일때 분모 → 0인 꼴이다.)

116 | 

117 | 다시 돌아와서 Δx → 0에서 Δu → 0이므로,

118 | 

119 | $dy/dx = [lim_{Δx → 0} (Δy/Δu)] × [d/dx g] = [lim_{Δu → 0} (Δy/Δu)] × [d/dx g]$ 이다.

120 | 

121 | 이제 남은 식을 풀이해야함은 당연히 그것이 목적이니 당연하다.

122 | 그러기 위해서 $lim_{Δu → 0} (Δy/Δu)$의 값을 구해야 한다.

123 | 당연히도, 우리가 아는 바에 의하면 직관적으로 ①을 구한것을 떠올릴 가능성이 높다. 저 식은 미분계수를 평균변화율로 나타낸 식이기에, 미분계수를 연상할 수 있기때문이다.

124 | 

125 | 다시 돌아와서

126 | 

127 | $dy/dx = [lim_{Δu → 0} (Δy/Δu)] × [d/dx g]$ 에서,

128 | 

129 | ①에 따라, $dy/du = lim_{Δu → 0} Δy/Δu$ 이므로,

130 | 

131 | $dy/dx = [lim_{Δu → 0} (Δy/Δu)] × [d/dx g] = [d/du f] × [d/dx g]$ 이다.

132 | 

133 | 도함수의 정의인 미분계수와 도함수가 같다는 점에 따라서,

134 | 

135 | 1. ý = f'(u) = dy/du이고

136 | 2. u = g(x)이므로,

137 | 3. ý = f'(g(x)) = dy/dy 이다.

138 | 

139 | 따라서, 

140 | 

141 | dy/dx = [d/du f] × [d/dx g] = ([d/dx f]◦g) × [d/dx g] 다.

142 | 즉, (d/dx) [f◦g] = [d/dx g] × ([d/dx f]◦g) 이다.

143 | 

144 | Q.E.D.

145 | 

146 | 이제, 뽀너스로 발견한것들을 적겠다

147 | 

148 | Δ(f × g) = fΔg + gΔf + ΔfΔg에서,

149 |

150 | d/dx (f × g)

151 | 

152 | = $lim_{Δx → 0} Δ(f × g)/Δx$

153 | 

154 | = $lim_{Δx → 0} {fΔg/Δx + gΔf/Δx + (ΔfΔg/(Δx)²)Δx}$

155 | = $lim_{Δx → 0} {f × g' + g × f' + (g' × f')Δx}$

156 | 

157 | 이렇게 Δy의 증분부분을 차분으로 바꾼후 분배해서 나눠서 미분으로 만들어도, Δx가 하나 남는다,

158 | 그런데 보통 우리다 미분이나 차분에서 h 혹은 Δx라는 기호를 어떻게 취급하는지 아는가?

159 | 

160 | 그러한 부분은 무한소로써 나눠지는 부분이다. (미분계수의 식이 바로 도함수이니, 그것에 대해서 무한소를 곱해주면 당연히 극한값이 0으로 가는 값과 곱해서 0으로 나오기에 0이다. 사실은 차분에서 나왔던 쓸대없는 계산부가 날아간거로 설명되지만...)

161 | 

162 | = $lim_{h → 0} {f × g' + g × f' + (g' × f')h}$

162 | 

163 | = f × g' + g × f'

164 |

165 | 참고로 교과서에서는 $lim_{h → 0) f(x + h) = f(x)$임을 이용한다.

166 |

167 | 표준부분원리인지 뭔지로 실수체계랑 같이 사용가능한 초실수체 `ℝ*`에서,

168 | 

169 | A. st(f*(x + ε)) = f(x)이고, 

170 | B. x = st(x) + ε (표준부분원리) 이기에,

171 | 

172 | 직관적으로, $lim_{h → 0) f(x + h) = f(x)$임이 당연하다는걸 알 수 있다.

173 | ad-equality `≈`에서,

174 | x + ε ≈ x 이며,

175 | st(x) + ε = x이고,

176 | $lim_{t → x} f(t) = f(x)$

177 | 이기에... 아 근데 아무도 의심하지 않는데 왜 내가 쓸때없는 소리를 하는지 모르겠다.

178 | 

179 | 

180 | ...

181 |

182 | 

183 | Calculate 연산자 Ca = (d/dx)라고 해보자.

184 | 

185 | 그러면, C¹ f, C¹ g및 a, b ∈ ℝ에서,

186 | Ca(af + bg) = a Ca(f) + b Ca(g) 이다, 

187 | 

188 | 즉, 미분 연산자 Ca는 선형이다.

189 | 

190 | 왜냐하면, 평균기울기 연산자 Δ/Δx = k Δ [k := 1/Δx]로, 차분연산자 Δ에 단순히 상수배를 해준걸로 취급... 뭐 ㅋㅋㅋ 변수배라고 하겠다 ㅋㅋㅋ 아니 농담이고,

191 | Δx를 보통 고정시켜서 실체있이 취급하기에 그렇게 말한거다.

192 |

193 | Δx에 대해, 차분연산자를 그 역수배해주면, 평균기울기 연산자다.

194 |

195 | 그런데, 차분은 선형이므로, 평균기울기 역시 선형이고, 

196 | 따라서 $lim_{Δx → 0}$으로 Δxᵤ = ε로 만들어버린 경우 역시나, 

197 | C¹ f, C¹ g에 대해, Ca (여기서는 d/dx라는 의미로써) 는 $lim_{Δx → 0} Δ/Δx$로,

198 | 

199 | 단지 모든 실수 Δx에 대해 전칭 양화하여 선형이었으므로, 당연히 극한으로 보냈어도 선형이다.

200 |

201 | 오미크론 ο에 대해서 서술한 다음에,

202 | 

203 | 중괄호 `{`, `}`안에 쓰인 오미크론 ο에 대해, ο → 0으로 보내주는걸 epsilon-delta-omicron-notation(edon)이라고 명명하겠다.

204 |

205 | edon은 Notation이다. 구문론적으로 정의되었고, 중괄호를 함수마냥 취급해서 그 안에있는 ο에 극한을 취해주는,

206 | 흡사 형식문법같이 작동하는 표기법 말이다.

207 | 

208 | 또한 ο = ε로 선언하는 경우을 epsilon-based-omicron-notation(ebon)이라고 하겠다.

209 | 

210 | ebon은 구문론적으로 ο를 ε로 선언하였으므로 ε에 할당된게, 비 유한 초실수 상수 중 무한소일수 있으며, 혹은 이원수 체계의 멱영원 ε = [[0, 1], [0, 0]]인 이차 정사각 행렬일수도 있다.

211 | 

212 | 뭐 메크로처럼 만들어논걸 쓰는건 표기법으로 적는사람 책임이지만 뭐... 못알아둬서 나쁠일은 솔찍히 별로다.

213 |

214 | 이러한 오미크론 표기법 (omicron-notation) 에 대해서,

215 | 

216 | 미분계수는 `dy/dx = Δy/Δx [Δx := ο]` 인걸로 볼수 있으므로,

217 | 

218 | 차분을 통하든 증분을 통하든, 거기서 거기. 같은 의미인지라, 완전히 다르게 정의해서 우선순위가 달라진 상태로써,

219 | `d/dx = Δ/Δx [Δx := ο]`으로써의 미분과, `dy/dx = Δy/Δx [Δx := ο]`으로써의 미분 계수에 대해서,

220 | 

221 | omicron-notation에 대한 미분연산자 (omicron만큼의 평균기울기 연산자인, 순간기울기) • 미분계수 (omicron만큼의 Δx증분을 통한 평균변화율인 미분걔수) 의 정의라고 하겠고,

222 | 이는 각각 "(× 1/ο)된 차분연산"과 "ο급 크기의 증분의 비"라는 대척점에 있는 관점이 되기에,

223 |

224 | 전자를 뉴턴식, 후자를 라이프니츠식이라고 부르겠다. 실제로 뉴턴이나 라이프니츠다 이렇게 생각했단건 아니고,

225 | 걍 이름을 붙이고싶은대 뭐가좋을까 싶다가, 라이벌인 두명을 떠올려서 히히...

226 | 

227 | "평균기울기의 극한과 미소의 비는 일반적인 미분 그 자체에 대한 관점과, 본질적인 관점이여서 다르다"고 말해도 되는지 모르겠다.

228 | 

229 | 암튼 뉴턴식은 추상적인 연산자 그 자체로써의 속성으로 몰빵하기 위해서 평균기울기에 극한을 달아주고, 라이프니츠식은 미소의 비라는 미분형식같은 관점이다....만.

230 | 

231 | 이렇게쓰는거 왠지 죄책감드니까 걍 뉴턴식 • 라이프니츠식 말고 "연산자식" • "미소비식"이라고 하겠다.

232 | 모르는상태에서 "새상 ×까라"는 식으로 탐구하니까, 속새의 이름을 더럽히지 말겠음.

233 |

234 | ! (본인의 지능이 열화되서 횡설수설한다는걸 깨닫은 나)

235 |

236 | 어이고, 힘들어서 뇌정지된것 같으니 내일이나 반나절정도 지나서 이야기하자
````